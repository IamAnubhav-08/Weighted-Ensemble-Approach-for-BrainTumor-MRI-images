{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob as glob\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394\n",
      "917\n"
     ]
    }
   ],
   "source": [
    "print(len(glob.glob(\"Evaluation/Test/**/*.jpg\")))\n",
    "print(len(glob.glob(\"Evaluation/Validation/**/*.jpg\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5712 files belonging to 4 classes.\n",
      "Found 917 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dir = \"Training\"\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=16,\n",
    "    image_size=(256, 256),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    interpolation='area'\n",
    ")\n",
    "\n",
    "valid_dir = \"Evaluation/Validation\"\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    valid_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=16,\n",
    "    image_size=(256, 256),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    interpolation='area'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load ResNet 152\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "vgg19_base = tf.keras.applications.VGG19(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(256,256,3),\n",
    ")\n",
    "\n",
    "for layer in vgg19_base.layers:\n",
    "    layer.trainable=False\n",
    "\n",
    "\n",
    "model.add(vgg19_base)\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_3D as sm\n",
    "focal_loss = sm.losses.CategoricalFocalLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "checkpoint =  tf.keras.callbacks.ModelCheckpoint(filepath ='model_checkpoints/vgg19_cc_loss.hdf5',\n",
    "                                                 verbose=1,\n",
    "                                                 monitor='val_accuracy',\n",
    "                                                 mode='max'\n",
    "                                                 )\n",
    "\n",
    "# Define some callbacks to improve training.\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "357/357 [==============================] - ETA: 0s - loss: 0.4879 - accuracy: 0.8223\n",
      "Epoch 1: saving model to model_checkpoints\\vgg19_cc_loss.hdf5\n",
      "357/357 [==============================] - 152s 424ms/step - loss: 0.4879 - accuracy: 0.8223 - val_loss: 0.3874 - val_accuracy: 0.8451 - lr: 1.0000e-04\n",
      "Epoch 2/15\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.2561 - accuracy: 0.9112\n",
      "Epoch 2: saving model to model_checkpoints\\vgg19_cc_loss.hdf5\n",
      "357/357 [==============================] - 149s 416ms/step - loss: 0.2561 - accuracy: 0.9112 - val_loss: 0.3143 - val_accuracy: 0.8735 - lr: 1.0000e-04\n",
      "Epoch 3/15\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.1964 - accuracy: 0.9338\n",
      "Epoch 3: saving model to model_checkpoints\\vgg19_cc_loss.hdf5\n",
      "357/357 [==============================] - 148s 414ms/step - loss: 0.1964 - accuracy: 0.9338 - val_loss: 0.2524 - val_accuracy: 0.9084 - lr: 1.0000e-04\n",
      "Epoch 4/15\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.1556 - accuracy: 0.9445\n",
      "Epoch 4: saving model to model_checkpoints\\vgg19_cc_loss.hdf5\n",
      "357/357 [==============================] - 148s 413ms/step - loss: 0.1556 - accuracy: 0.9445 - val_loss: 0.2017 - val_accuracy: 0.9248 - lr: 1.0000e-04\n",
      "Epoch 5/15\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.1145 - accuracy: 0.9652\n",
      "Epoch 5: saving model to model_checkpoints\\vgg19_cc_loss.hdf5\n",
      "357/357 [==============================] - 148s 413ms/step - loss: 0.1145 - accuracy: 0.9652 - val_loss: 0.1919 - val_accuracy: 0.9269 - lr: 1.0000e-04\n",
      "Epoch 6/15\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.1060 - accuracy: 0.9671\n",
      "Epoch 6: saving model to model_checkpoints\\vgg19_cc_loss.hdf5\n",
      "357/357 [==============================] - 147s 411ms/step - loss: 0.1060 - accuracy: 0.9671 - val_loss: 0.2522 - val_accuracy: 0.9062 - lr: 1.0000e-04\n",
      "Epoch 7/15\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.0761 - accuracy: 0.9804\n",
      "Epoch 7: saving model to model_checkpoints\\vgg19_cc_loss.hdf5\n",
      "357/357 [==============================] - 148s 414ms/step - loss: 0.0761 - accuracy: 0.9804 - val_loss: 0.1551 - val_accuracy: 0.9378 - lr: 1.0000e-04\n",
      "Epoch 8/15\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.0615 - accuracy: 0.9870\n",
      "Epoch 8: saving model to model_checkpoints\\vgg19_cc_loss.hdf5\n",
      "357/357 [==============================] - 147s 411ms/step - loss: 0.0615 - accuracy: 0.9870 - val_loss: 0.1390 - val_accuracy: 0.9498 - lr: 1.0000e-04\n",
      "Epoch 9/15\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.0569 - accuracy: 0.9860\n",
      "Epoch 9: saving model to model_checkpoints\\vgg19_cc_loss.hdf5\n",
      "357/357 [==============================] - 147s 412ms/step - loss: 0.0569 - accuracy: 0.9860 - val_loss: 0.1452 - val_accuracy: 0.9444 - lr: 1.0000e-04\n",
      "Epoch 10/15\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.0446 - accuracy: 0.9911\n",
      "Epoch 10: saving model to model_checkpoints\\vgg19_cc_loss.hdf5\n",
      "357/357 [==============================] - 148s 413ms/step - loss: 0.0446 - accuracy: 0.9911 - val_loss: 0.1228 - val_accuracy: 0.9607 - lr: 1.0000e-04\n",
      "Epoch 11/15\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.0346 - accuracy: 0.9940\n",
      "Epoch 11: saving model to model_checkpoints\\vgg19_cc_loss.hdf5\n",
      "357/357 [==============================] - 148s 414ms/step - loss: 0.0346 - accuracy: 0.9940 - val_loss: 0.1212 - val_accuracy: 0.9531 - lr: 1.0000e-04\n",
      "Epoch 12/15\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.0361 - accuracy: 0.9930\n",
      "Epoch 12: saving model to model_checkpoints\\vgg19_cc_loss.hdf5\n",
      "357/357 [==============================] - 106s 298ms/step - loss: 0.0361 - accuracy: 0.9930 - val_loss: 0.1494 - val_accuracy: 0.9455 - lr: 1.0000e-04\n",
      "Epoch 13/15\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.0324 - accuracy: 0.9933\n",
      "Epoch 13: saving model to model_checkpoints\\vgg19_cc_loss.hdf5\n",
      "357/357 [==============================] - 70s 195ms/step - loss: 0.0324 - accuracy: 0.9933 - val_loss: 0.1132 - val_accuracy: 0.9575 - lr: 1.0000e-04\n",
      "Epoch 14/15\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 0.9965\n",
      "Epoch 14: saving model to model_checkpoints\\vgg19_cc_loss.hdf5\n",
      "357/357 [==============================] - 70s 197ms/step - loss: 0.0236 - accuracy: 0.9965 - val_loss: 0.1020 - val_accuracy: 0.9586 - lr: 1.0000e-04\n",
      "Epoch 15/15\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 0.9986\n",
      "Epoch 15: saving model to model_checkpoints\\vgg19_cc_loss.hdf5\n",
      "357/357 [==============================] - 71s 199ms/step - loss: 0.0180 - accuracy: 0.9986 - val_loss: 0.0974 - val_accuracy: 0.9640 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "history_vgg19 = model.fit(train_ds,\n",
    "                          validation_data=val_ds,\n",
    "                          epochs=epochs,\n",
    "                          callbacks=[early_stopping, reduce_lr, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.0184 - accuracy: 0.9979\n",
      "Epoch 1: saving model to model_checkpoints\\vgg19_cc_loss.hdf5\n",
      "357/357 [==============================] - 70s 195ms/step - loss: 0.0184 - accuracy: 0.9979 - val_loss: 0.1000 - val_accuracy: 0.9640 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.0145 - accuracy: 0.9988\n",
      "Epoch 2: saving model to model_checkpoints\\vgg19_cc_loss.hdf5\n",
      "357/357 [==============================] - 70s 197ms/step - loss: 0.0145 - accuracy: 0.9988 - val_loss: 0.0958 - val_accuracy: 0.9673 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.9989\n",
      "Epoch 3: saving model to model_checkpoints\\vgg19_cc_loss.hdf5\n",
      "357/357 [==============================] - 71s 199ms/step - loss: 0.0116 - accuracy: 0.9989 - val_loss: 0.0905 - val_accuracy: 0.9640 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.9996\n",
      "Epoch 4: saving model to model_checkpoints\\vgg19_cc_loss.hdf5\n",
      "357/357 [==============================] - 72s 201ms/step - loss: 0.0084 - accuracy: 0.9996 - val_loss: 0.0910 - val_accuracy: 0.9662 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.0267 - accuracy: 0.9919\n",
      "Epoch 5: saving model to model_checkpoints\\vgg19_cc_loss.hdf5\n",
      "357/357 [==============================] - 71s 199ms/step - loss: 0.0267 - accuracy: 0.9919 - val_loss: 0.1400 - val_accuracy: 0.9520 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 0.9988\n",
      "Epoch 6: saving model to model_checkpoints\\vgg19_cc_loss.hdf5\n",
      "357/357 [==============================] - 71s 198ms/step - loss: 0.0096 - accuracy: 0.9988 - val_loss: 0.0890 - val_accuracy: 0.9695 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 7: saving model to model_checkpoints\\vgg19_cc_loss.hdf5\n",
      "357/357 [==============================] - 71s 199ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0877 - val_accuracy: 0.9640 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 8: saving model to model_checkpoints\\vgg19_cc_loss.hdf5\n",
      "357/357 [==============================] - 71s 199ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0853 - val_accuracy: 0.9684 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.9995\n",
      "Epoch 9: saving model to model_checkpoints\\vgg19_cc_loss.hdf5\n",
      "357/357 [==============================] - 71s 198ms/step - loss: 0.0049 - accuracy: 0.9995 - val_loss: 0.0872 - val_accuracy: 0.9684 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 10: saving model to model_checkpoints\\vgg19_cc_loss.hdf5\n",
      "357/357 [==============================] - 71s 198ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0904 - val_accuracy: 0.9673 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "vgg19_base.trainable = True\n",
    "for layer in vgg19_base.layers[:10]:\n",
    "    layer.trainable=False\n",
    "    \n",
    "fine_tune_history_vgg19 = model.fit(train_ds,\n",
    "                          validation_data=val_ds,\n",
    "                          epochs=epochs-5,\n",
    "                          callbacks=[early_stopping, reduce_lr, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 394 files belonging to 4 classes.\n",
      "25/25 [==============================] - 7s 278ms/step - loss: 0.0439 - accuracy: 0.9848\n"
     ]
    }
   ],
   "source": [
    "test_dir = \"Evaluation/Test\"\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=16,\n",
    "    image_size=(256, 256),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    interpolation='area'\n",
    ")\n",
    "test_ds = test_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "score = model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = fine_tune_history_resnet50\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(5,8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,0.1])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
